{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15701f37-33e3-4e2c-ada2-f187c5960669",
   "metadata": {},
   "source": [
    "# Building a Chatbot with NLP and GRU model and attention mechanism\n",
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afbe20e-04a5-455d-82c4-524ec8e9436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable = True)\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, GRU, LSTM, Masking\n",
    "import json\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59be0d0-fc3f-45cd-ad40-9fdb60c0c41d",
   "metadata": {},
   "source": [
    "### Importing preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22e1590-6c26-4262-859c-8fce0e1136cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./preprocessed_data/questions.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    question_corpus = tokenizer_from_json(json_data)\n",
    "    f.close()\n",
    "\n",
    "with open('./preprocessed_data/answers.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    answer_corpus = tokenizer_from_json(json_data)\n",
    "    f.close()\n",
    "\n",
    "npzfile = np.load('./preprocessed_data/data.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6345dd16-17f6-4056-8fa0-d76275898723",
   "metadata": {},
   "source": [
    "#### Some unknown reason make the corpus contain all words and labels in raw data rather than a vocabulary with limited size so we have to build the dict manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d529a9d-e273-4824-ad4d-9751f0a709d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_word2ind = {e:i for e, i in question_corpus.word_index.items() if i <= 5001}\n",
    "q_ind2word = {e:i for i, e in q_word2ind.items()}\n",
    "a_word2ind = {e:i for e, i in answer_corpus.word_index.items() if i <= 5001}\n",
    "a_ind2word = {e:i for i, e in a_word2ind.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e4d7ce-1c98-485b-8e91-3c3db9f98dcf",
   "metadata": {},
   "source": [
    "### Creating the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f92d4a9-8df7-4014-8104-1eb658baf031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(inputdim, embeddingsize, inputlen, n_units):\n",
    "\n",
    "    encoder_input = Input((inputlen,))\n",
    "    encoder_embed = Embedding(inputdim, embeddingsize)(encoder_input)\n",
    "    encoder_mask = Masking()(encoder_embed)\n",
    "    \n",
    "    encoder = GRU(n_units, return_sequences = True, return_state = True)\n",
    "    encoder_output, encoder_state = encoder(encoder_mask)\n",
    "    \n",
    "    encoder=Model(encoder_input, [encoder_output, encoder_state])\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06dc808-09d7-4c6a-969d-18a79ff22d3f",
   "metadata": {},
   "source": [
    "### Creating the Bahdanau Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3fbde74-2b8a-4d2a-9977-21de117969b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis = 1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c002a0-57e9-49d5-b4c1-bc934b897262",
   "metadata": {},
   "source": [
    "### Creating the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "046890c6-b4c1-4077-b476-321803fbe4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decoder(inputdim, embeddingsize, inputlen, units):\n",
    "    \n",
    "    # The size of input at here is 1 because we want to predict the answer step by step, each time only input 1 word\n",
    "    dec_input = Input((1,))\n",
    "    \n",
    "    # Vectorizing input answers\n",
    "    dec_embed = Embedding(inputdim, embeddingsize)(dec_input)\n",
    "    \n",
    "    # Input of encoder state vectors\n",
    "    enc_output = Input((inputlen, units, ))\n",
    "    hidden = Input((units, ))\n",
    "    context_vector,attention_weights = BahdanauAttention(units)(hidden, enc_output)\n",
    "\n",
    "    context_expand = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, 1))(context_vector)\n",
    "    full_context = tf.concat([tf.expand_dims(context_vector, 1), dec_embed], axis = -1)\n",
    "\n",
    "    output, state = GRU(units, return_sequences = True, return_state = True)(full_context)\n",
    "\n",
    "    flat_output = tf.keras.layers.Flatten()(output)\n",
    "    \n",
    "    # Using activation function as softmax layer, predict the most potential sentence of reply\n",
    "    decoder_output = Dense(inputdim, activation = 'softmax')(flat_output)\n",
    "\n",
    "    decoder = Model([enc_output, hidden, dec_input], [decoder_output, state])\n",
    "\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542af7c3-2da7-4b94-befc-e0b96d90c078",
   "metadata": {},
   "source": [
    "### Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5faed8f7-7cd4-428e-b752-7dd5348d52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5001\n",
    "embedding_size = 128\n",
    "n_unit = 256\n",
    "batch_size = 64\n",
    "question_len = npzfile['arr_0'].shape[1]\n",
    "answer_len = npzfile['arr_1'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aedc0358-8fb2-4774-888e-0b94d932d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size, embedding_size, question_len, n_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5610c7f9-a575-4dc5-8c57-2edb01649c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 21, 128)           640128    \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    [(None, 21, 256), (None,  296448    \n",
      "=================================================================\n",
      "Total params: 936,576\n",
      "Trainable params: 936,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2aacf62-5a70-462c-8b0d-83a3eae14820",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_size, embedding_size, question_len, n_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb3d3b38-7a80-4d57-8991-a5e80bc4c5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 21, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bahdanau_attention (BahdanauAtt ((None, 256), (None, 131841      input_4[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims (TFOpLambda)     (None, 1, 256)       0           bahdanau_attention[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 128)       640128      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 1, 384)       0           tf.expand_dims[0][0]             \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, 1, 256), (No 493056      tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 256)          0           gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5001)         1285257     flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,550,282\n",
      "Trainable params: 2,550,282\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbc8f4e0-6bfa-4fdf-b541-9176fd6f7b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_weights('./trained_model/attention_encoder_test5000.h5')\n",
    "decoder.load_weights('./trained_model/attention_decoder_test5000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1971ad0a-11dd-4830-beb4-b86b1949adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    # Remove unnecessary characters in sentences\n",
    "    \n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3cd1d3-b4ba-48fc-b55e-743d68853259",
   "metadata": {},
   "source": [
    "### Evaluating the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59f2ed74-081e-4bd9-bfbc-c235ff877d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    \n",
    "    # Cleaning the input text\n",
    "    sentence = clean_text(sentence) \n",
    "    encoder_inputs = []\n",
    "    \n",
    "    # Converting the input text to index sequence and use unk replace the word not in vocabulary\n",
    "    for word in sentence.split():\n",
    "        if word in q_word2ind.keys():\n",
    "            encoder_inputs.append(q_word2ind[word])\n",
    "        elif word not in q_word2ind.keys():\n",
    "            encoder_inputs.append(q_word2ind['unk'])\n",
    "            \n",
    "    encoder_inputs = tf.keras.preprocessing.sequence.pad_sequences([encoder_inputs], maxlen = question_len, padding = 'post')\n",
    "    encoder_inputs = tf.convert_to_tensor(encoder_inputs)\n",
    "    encoder_output, encoder_state = encoder(encoder_inputs)\n",
    "    \n",
    "    hidden_state = encoder_state\n",
    "    decoder_input = tf.expand_dims([a_word2ind['bos']], 0)\n",
    "    \n",
    "    result = ''\n",
    "    \n",
    "    for t in range(answer_len):\n",
    "        pred, state = decoder([encoder_output, hidden_state, decoder_input])\n",
    "        pred = np.squeeze(pred)\n",
    "        pred_ind = tf.math.argmax(pred).numpy()\n",
    "        \n",
    "        if a_ind2word[pred_ind] == 'eos':\n",
    "            return result\n",
    "\n",
    "        result += a_ind2word[pred_ind] + ' '\n",
    "        \n",
    "        # Passing the predict index and state vectors to the next input\n",
    "        decoder_input = tf.expand_dims([pred_ind],0)\n",
    "        hidden_state = state\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b025e3c8-81b4-463c-9d5a-ddab2cd6f0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> hello unk \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> hi \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  how are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> fine i am fine \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  really?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> i am sorry \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  where are you from\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> unk \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  where are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> i am here \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  the news is great\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> what is the unk \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  that girl is beautiful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> unk \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  sweet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> i will be unk \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  nice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> thanks \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  lets see other\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> and what about \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  movies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> thank you \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  you are welcome\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot :> i am going to be unk \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User :>  quit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    inputs = input('User :> ')\n",
    "    if inputs == 'quit':\n",
    "        break\n",
    "\n",
    "    result = evaluate(inputs)\n",
    "\n",
    "    print('Bot :> ' + result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafa3876-ed38-4742-9bf9-3868988b9c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
